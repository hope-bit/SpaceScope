import h5py
import numpy as np

# Paths to datasets
train_file_path = 'C:/Users/HopeW/Downloads/MEM679_Project/SpaceScope/galaxy_mnist/GalaxyMNIST/raw/train_dataset.hdf5'
test_file_path = 'C:/Users/HopeW/Downloads/MEM679_Project/SpaceScope/galaxy_mnist/GalaxyMNIST/raw/test_dataset.hdf5'

# Load training dataset
with h5py.File(train_file_path, 'r') as train_file:
    X_train = train_file['images'][:] / 255.0  # Normalize to [0, 1]
    y_train = train_file['labels'][:]

# Load test dataset
with h5py.File(test_file_path, 'r') as test_file:
    X_test = test_file['images'][:] / 255.0  # Normalize to [0, 1]
    y_test = test_file['labels'][:]

y_train = np.squeeze(y_train)
y_test = np.squeeze(y_test)


import tensorflow as tf
import keras
from keras import Sequential, layers, models
from keras._tf_keras.keras.utils import to_categorical

# Convert labels to one-hot encoding
#from sklearn.preprocessing import OneHotEncoder
print("y_train shape:", y_train.shape)
print("y_train values:", y_train[:10])  # Print first 10 values to inspect
print("y_test shape:", y_test.shape)
print("y_test values:", y_test[:10])

# One-hot encode labels
y_train_one_hot = to_categorical(y_train, num_classes=4)
y_test_one_hot = to_categorical(y_test, num_classes=4)

print("y_train_one_hot shape:", y_train_one_hot.shape)
print("y_test_one_hot shape:", y_test_one_hot.shape)
y_train_one_hot = y_train_one_hot.astype('float32')
y_test_one_hot = y_test_one_hot.astype('float32')


# Define the model
model = models.Sequential([
    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(64, 64, 3)),
    layers.MaxPooling2D(),
    layers.BatchNormalization(),
    layers.Conv2D(64, (3, 3), activation='relu'),
    layers.MaxPooling2D(),
    layers.BatchNormalization(),
    layers.Conv2D(128, (3, 3), activation='relu'),
    layers.MaxPooling2D(),
    layers.BatchNormalization(),
    layers.Conv2D(256, (3, 3), activation='relu'),
    layers.MaxPooling2D(),
    layers.BatchNormalization(),
    layers.Flatten(),
    
    layers.Dense(512, activation='relu'),
    layers.Dropout(0.7),  # Add dropout to prevent overfitting
    
    layers.Dense(4, activation='softmax')  # Output layer with 4 classes
])

# Compile the model
from keras._tf_keras.keras.optimizers import RMSprop

model.compile(optimizer=RMSprop(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])

# Print model summary
model.summary()
print(model.output_shape)

from keras._tf_keras.keras.preprocessing.image import ImageDataGenerator
#Create an ImageDataGenerator instance for data augmentation
datagen = ImageDataGenerator(
    rotation_range=20,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True,
    fill_mode='nearest'
)

# Fit the generator to your training data
datagen.fit(X_train)

from keras._tf_keras.keras.callbacks import LearningRateScheduler, ReduceLROnPlateau, EarlyStopping
# Reduce learning rate on plateau
lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=0.00001)

# Early stopping
early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)

# Train the model with augmented data and callbacks
history = model.fit(
    datagen.flow(X_train, y_train_one_hot, batch_size=32),
    epochs=20,
    validation_data=(X_test, y_test_one_hot),
    callbacks=[lr_scheduler, early_stopping]  # Ensure callbacks are passed correctly
)

# Evaluate on test dataset
test_loss, test_accuracy = model.evaluate(X_test, y_test_one_hot)
print(f"Test Accuracy: {test_accuracy:.2f}")

import matplotlib.pyplot as plt

# Plot training and validation accuracy
plt.figure(figsize=(10, 5))
plt.plot(history.history['accuracy'], label='Train Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()
plt.title('Training and Validation Accuracy')
plt.show()

# Save the model
model.save('galaxy_mnist_classifierH5.h5')
model.save('galaxy_mnist_classifierK.keras')

# Load and predict
loaded_model = tf.keras.models.load_model('galaxy_mnist_classifierK.keras')
predictions = loaded_model.predict(X_test)
predicted_classes = np.argmax(predictions, axis=1)
